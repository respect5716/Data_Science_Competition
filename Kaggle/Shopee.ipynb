{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Baseline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## 0. Info","metadata":{}},{"cell_type":"markdown","source":"### Features\n* Image hash + Image embedding + Text embedding\n* Image embedding: pretrained resnet50\n* Text embedding: TF-IDF\n\n\n### Reference\n* https://www.kaggle.com/finlay/unsupervised-image-text-baseline-in-20min","metadata":{}},{"cell_type":"markdown","source":"## 1. Setting","metadata":{}},{"cell_type":"code","source":"# Libraries\nimport os\nfrom glob import glob\nfrom tqdm.auto import tqdm\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nfrom sklearn.preprocessing import normalize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class CONFIG:\n    img_size = 256\n    chunk_size = 1024\n    batch_size = 32\n    data_dir = '../input/shopee-product-matching'\n    phase = 'train' if len(pd.read_csv(os.path.join(data_dir, 'test.csv'))) == 3 else 'test'\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data","metadata":{}},{"cell_type":"code","source":"def f1_score(true:list, pred:list):\n    intersection = set(true) & set(pred)\n    f1 = 2 * len(intersection) / (len(true) + len(pred))\n    return f1","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(os.path.join(CONFIG.data_dir, f'{CONFIG.phase}.csv'))\ndata['image'] = data['image'].apply(lambda x : os.path.join(CONFIG.data_dir, 'train_images', x))\ndata.head()","metadata":{"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"         posting_id                                              image  \\\n0   train_129225211  ../input/shopee-product-matching/train_images/...   \n1  train_3386243561  ../input/shopee-product-matching/train_images/...   \n2  train_2288590299  ../input/shopee-product-matching/train_images/...   \n3  train_2406599165  ../input/shopee-product-matching/train_images/...   \n4  train_3369186413  ../input/shopee-product-matching/train_images/...   \n\n        image_phash                                              title  \\\n0  94974f937d4c2433                          Paper Bag Victoria Secret   \n1  af3f9460c2838f0f  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   \n2  b94cb00ed3e50f78        Maling TTS Canned Pork Luncheon Meat 397 gr   \n3  8514fc58eafea283  Daster Batik Lengan pendek - Motif Acak / Camp...   \n4  a6f319f924ad708c                  Nescafe \\xc3\\x89clair Latte 220ml   \n\n   label_group  \n0    249114794  \n1   2937985045  \n2   2395904891  \n3   4093212188  \n4   3648931069  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>posting_id</th>\n      <th>image</th>\n      <th>image_phash</th>\n      <th>title</th>\n      <th>label_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_129225211</td>\n      <td>../input/shopee-product-matching/train_images/...</td>\n      <td>94974f937d4c2433</td>\n      <td>Paper Bag Victoria Secret</td>\n      <td>249114794</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_3386243561</td>\n      <td>../input/shopee-product-matching/train_images/...</td>\n      <td>af3f9460c2838f0f</td>\n      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n      <td>2937985045</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2288590299</td>\n      <td>../input/shopee-product-matching/train_images/...</td>\n      <td>b94cb00ed3e50f78</td>\n      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n      <td>2395904891</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_2406599165</td>\n      <td>../input/shopee-product-matching/train_images/...</td>\n      <td>8514fc58eafea283</td>\n      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n      <td>4093212188</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_3369186413</td>\n      <td>../input/shopee-product-matching/train_images/...</td>\n      <td>a6f319f924ad708c</td>\n      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n      <td>3648931069</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Shape\")\ndisplay(data.shape)\nprint('\\n')\n\nprint(\"Info\")\ndisplay(data.info())\nprint('\\n')\n\nprint(\"Nunique\")\ndisplay(data.nunique())","metadata":{"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Shape\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(34250, 5)"},"metadata":{}},{"name":"stdout","text":"\n\nInfo\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 34250 entries, 0 to 34249\nData columns (total 5 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   posting_id   34250 non-null  object\n 1   image        34250 non-null  object\n 2   image_phash  34250 non-null  object\n 3   title        34250 non-null  object\n 4   label_group  34250 non-null  int64 \ndtypes: int64(1), object(4)\nmemory usage: 1.3+ MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}},{"name":"stdout","text":"\n\nNunique\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"posting_id     34250\nimage          32412\nimage_phash    28735\ntitle          33117\nlabel_group    11014\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"if CONFIG.phase == 'train':\n    group_members = data.groupby('label_group')['posting_id'].agg('unique').to_dict()\n    data['true_matches'] = data['label_group'].map(group_members)\n    display(data.head())","metadata":{"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"         posting_id                                              image  \\\n0   train_129225211  ../input/shopee-product-matching/train_images/...   \n1  train_3386243561  ../input/shopee-product-matching/train_images/...   \n2  train_2288590299  ../input/shopee-product-matching/train_images/...   \n3  train_2406599165  ../input/shopee-product-matching/train_images/...   \n4  train_3369186413  ../input/shopee-product-matching/train_images/...   \n\n        image_phash                                              title  \\\n0  94974f937d4c2433                          Paper Bag Victoria Secret   \n1  af3f9460c2838f0f  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   \n2  b94cb00ed3e50f78        Maling TTS Canned Pork Luncheon Meat 397 gr   \n3  8514fc58eafea283  Daster Batik Lengan pendek - Motif Acak / Camp...   \n4  a6f319f924ad708c                  Nescafe \\xc3\\x89clair Latte 220ml   \n\n   label_group                          true_matches  \n0    249114794   [train_129225211, train_2278313361]  \n1   2937985045  [train_3386243561, train_3423213080]  \n2   2395904891  [train_2288590299, train_3803689425]  \n3   4093212188  [train_2406599165, train_3342059966]  \n4   3648931069   [train_3369186413, train_921438619]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>posting_id</th>\n      <th>image</th>\n      <th>image_phash</th>\n      <th>title</th>\n      <th>label_group</th>\n      <th>true_matches</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_129225211</td>\n      <td>../input/shopee-product-matching/train_images/...</td>\n      <td>94974f937d4c2433</td>\n      <td>Paper Bag Victoria Secret</td>\n      <td>249114794</td>\n      <td>[train_129225211, train_2278313361]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_3386243561</td>\n      <td>../input/shopee-product-matching/train_images/...</td>\n      <td>af3f9460c2838f0f</td>\n      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n      <td>2937985045</td>\n      <td>[train_3386243561, train_3423213080]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2288590299</td>\n      <td>../input/shopee-product-matching/train_images/...</td>\n      <td>b94cb00ed3e50f78</td>\n      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n      <td>2395904891</td>\n      <td>[train_2288590299, train_3803689425]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_2406599165</td>\n      <td>../input/shopee-product-matching/train_images/...</td>\n      <td>8514fc58eafea283</td>\n      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n      <td>4093212188</td>\n      <td>[train_2406599165, train_3342059966]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_3369186413</td>\n      <td>../input/shopee-product-matching/train_images/...</td>\n      <td>a6f319f924ad708c</td>\n      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n      <td>3648931069</td>\n      <td>[train_3369186413, train_921438619]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"image_hash_members = data.groupby('image_phash')['posting_id'].agg('unique').to_dict()\ndata['hash_matches'] = data['image_phash'].map(image_hash_members)\ndata['hash_matches'] = data['hash_matches'].apply(list)","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"if CONFIG.phase == 'train':\n    data['hash_f1'] = data.apply(lambda x : f1_score(x['true_matches'], x['hash_matches']), axis=1)\n    hash_f1 = data['hash_f1'].mean()\n    print(f'hash f1: {hash_f1:.3f}')","metadata":{"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"hash f1: 0.553\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3. Model","metadata":{}},{"cell_type":"code","source":"def predict(features, threshold=0.9):\n    preds = []\n    length = len(features) // CONFIG.chunk_size\n    if len(features) % CONFIG.chunk_size != 0: length += 1\n        \n    for i in tqdm(range(length)):\n        l = CONFIG.chunk_size * i\n        r = CONFIG.chunk_size * (i + 1)\n        r = min(r, len(features))\n        \n        sim = torch.matmul(features, features[l:r].T).T\n        sim = sim.data.cpu().numpy()\n        \n        for j in range(len(sim)):\n            idx = np.where(sim[j] > threshold)[0]\n            preds.append(data.iloc[idx]['posting_id'].to_list())\n    \n    return preds","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Image","metadata":{}},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, image_path, transform=None):\n        self.image_path = image_path\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.image_path)\n    \n    def __getitem__(self, idx):\n        img = Image.open(self.image_path[idx]).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((CONFIG.img_size, CONFIG.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])\n\ndataset = Dataset(data['image'].tolist(), transform)\ndataloader = torch.utils.data.DataLoader(dataset, CONFIG.batch_size, shuffle=False)\n\nx = next(iter(dataloader))\nx.size()","metadata":{"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"torch.Size([32, 3, 256, 256])"},"metadata":{}}]},{"cell_type":"code","source":"class ImageModel(nn.Module):\n    def __init__(self):\n        super(ImageModel, self).__init__()\n        # Download pretrained weights and upload to the dataset\n        # 'https://download.pytorch.org/models/resnet50-0676ba61.pth'\n        model = torchvision.models.resnet50()\n        weights = torch.load('../input/pytorch-models/resnet50.pth')\n        model.load_state_dict(weights)\n        self.featurizer = nn.Sequential(*list(model.children())[:-2])\n        self.pool = nn.AdaptiveMaxPool2d(1)\n        self.flatten = nn.Flatten()\n        \n    def forward(self, x):\n        x = self.featurizer(x)\n        x = self.pool(x)\n        x = self.flatten(x)\n        return x","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"image_model = ImageModel().to(CONFIG.device)\nimage_model = image_model.eval()","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"image_features = []\nwith torch.no_grad():\n    for x in tqdm(dataloader):\n        x = x.to(CONFIG.device)\n        feat = image_model(x)\n        feat = feat.data.cpu().numpy()\n        image_features.append(feat)\n\nimage_features = np.vstack(image_features)\nimage_features = normalize(image_features)\nimage_features = torch.from_numpy(image_features).to(CONFIG.device)","metadata":{"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1071 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d95a7d7b68314c57aec2b5e78219a6c1"}},"metadata":{}}]},{"cell_type":"code","source":"image_matches = predict(image_features, threshold=0.95)\ndata['image_matches'] = image_matches","metadata":{"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/34 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e639f10b0cbb4894b3a66e2037f48933"}},"metadata":{}}]},{"cell_type":"code","source":"if CONFIG.phase == 'train':\n    data['image_f1'] = data.apply(lambda x : f1_score(x['true_matches'], x['image_matches']), axis=1)\n    image_f1 = data['image_f1'].mean()\n    print(f'image f1: {image_f1:.3f}')","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"image f1: 0.635\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Title","metadata":{}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(max_features=50000)","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"text_features = vectorizer.fit_transform(data['title']).toarray()\ntext_features = torch.from_numpy(text_features).to(CONFIG.device)","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"text_matches = predict(text_features, threshold=0.7)\ndata['text_matches'] = text_matches","metadata":{"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/34 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c6684aa61a04328aaf79fc44b5471ce"}},"metadata":{}}]},{"cell_type":"code","source":"if CONFIG.phase == 'train':\n    data['text_f1'] = data.apply(lambda x : f1_score(x['true_matches'], x['text_matches']), axis=1)\n    text_f1 = data['text_f1'].mean()\n    print(f'text f1: {text_f1:.3f}')","metadata":{"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"text f1: 0.617\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Total","metadata":{}},{"cell_type":"code","source":"data['total_matches'] = data.apply(lambda x : list(set(x['hash_matches'] + x['image_matches'] + x['text_matches'])), axis=1)","metadata":{"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"if CONFIG.phase == 'train':\n    data['total_f1'] = data.apply(lambda x : f1_score(x['true_matches'], x['total_matches']), axis=1)\n    total_f1 = data['total_f1'].mean()\n    print(f'total f1: {total_f1:.3f}')","metadata":{"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"total f1: 0.723\n","output_type":"stream"}]},{"cell_type":"code","source":"submission = pd.DataFrame({'posting_id':data['posting_id'], 'matches':data['total_matches']})\nsubmission['matches'] = submission['matches'].apply(lambda x : ' '.join(x))\nsubmission.head()","metadata":{"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"         posting_id                                            matches\n0   train_129225211                   train_129225211 train_2278313361\n1  train_3386243561                                   train_3386243561\n2  train_2288590299                                   train_2288590299\n3  train_2406599165  train_1744956981 train_3576714541 train_240659...\n4  train_3369186413                                   train_3369186413","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>posting_id</th>\n      <th>matches</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_129225211</td>\n      <td>train_129225211 train_2278313361</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_3386243561</td>\n      <td>train_3386243561</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2288590299</td>\n      <td>train_2288590299</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_2406599165</td>\n      <td>train_1744956981 train_3576714541 train_240659...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_3369186413</td>\n      <td>train_3369186413</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":24,"outputs":[]}]}