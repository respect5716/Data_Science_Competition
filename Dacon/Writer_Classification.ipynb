{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_scratch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlW6W37X86Ez"
      },
      "source": [
        "# 소설 작가 분류 AI 경진대회"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGrq7uSZ9Eyf"
      },
      "source": [
        "## 0. Info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGfN-A3f9HAF"
      },
      "source": [
        "* Type : Text Classification\n",
        "* URL : https://dacon.io/competitions/official/235670/data/\n",
        "* score\n",
        "    * train (log) :\n",
        "    * val (log) :\n",
        "    * test (lb) :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3G6s-A39J2u"
      },
      "source": [
        "## 1. Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_MfAHle9czN"
      },
      "source": [
        "!pip install -q sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnIkaSIh9NWd"
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import sentencepiece as spm\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7upAXyja9kT0"
      },
      "source": [
        "SEED = 1\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJgIxKRI9laE"
      },
      "source": [
        "MAX_LENGTH = 128\n",
        "MODEL_DIM = 128\n",
        "DFF = 128\n",
        "NUM_HEAD = 4\n",
        "NUM_LAYER = 4\n",
        "NUM_TOKEN = 10000\n",
        "DROP_RATE = 0.2\n",
        "BATCH_SIZE = 32\n",
        "EPOCH_SIZE = 10\n",
        "BASE_DIR = 'drive/Shared drives/Yoon/Project/Doing/Data Science Competition/Dacon/Writer Classification'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2nIpBjU9O71"
      },
      "source": [
        "## 2. Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq2m1UWm9_uF"
      },
      "source": [
        "class Dataloader(tf.keras.utils.Sequence):\n",
        "    def __init__(self, data, tokenizer, mode):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.mode = mode\n",
        "\n",
        "        self.on_epoch_end()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return np.ceil(len(self.data) / BATCH_SIZE).astype(np.int32)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.mode == 'train':\n",
        "            self.indices = np.random.permutation(len(self.data))\n",
        "        else:\n",
        "            self.indices = np.arange(len(self.data))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        batch_idx = self.indices[BATCH_SIZE*idx : BATCH_SIZE*(idx+1)]\n",
        "        batch_data = self.data.iloc[batch_idx]\n",
        "        batch_x = batch_data['text']\n",
        "        batch_x = [self.tokenizer.encode(x) for x in batch_x]\n",
        "        batch_x = tf.keras.preprocessing.sequence.pad_sequences(batch_x, maxlen=MAX_LENGTH)\n",
        "        batch_x = batch_x.astype(np.int32)\n",
        "\n",
        "        if self.mode == 'test':\n",
        "            batch_y = None\n",
        "        else:\n",
        "            batch_y = batch_data['author'].values.astype(np.int32)\n",
        "        return batch_x, batch_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJPfK5tn9jCM"
      },
      "source": [
        "data_path = os.path.join(BASE_DIR, 'data.zip')\n",
        "!unzip -q \"{data_path}\" -d \"data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "he0AsWA29oVN",
        "outputId": "37eda9dc-0676-49b2-853c-c475da016853"
      },
      "source": [
        "train_data = pd.read_csv('data/train.csv', index_col=0)\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He was almost choking. There was so much, so m...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“Your sister asked for it, I suppose?”</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>She was engaged one day as she walked, in per...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The captain was in the porch, keeping himself ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  author\n",
              "index                                                           \n",
              "0      He was almost choking. There was so much, so m...       3\n",
              "1                 “Your sister asked for it, I suppose?”       2\n",
              "2       She was engaged one day as she walked, in per...       1\n",
              "3      The captain was in the porch, keeping himself ...       4\n",
              "4      “Have mercy, gentlemen!” odin flung up his han...       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "9jY5kxqHKtaD",
        "outputId": "209fabaa-b0b1-472d-8977-a5eaa8a5d7f5"
      },
      "source": [
        "train_data['len'] = train_data['text'].apply(len)\n",
        "train_data.groupby('author')['len'].agg(['min', 'mean', 'max'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min</th>\n",
              "      <th>mean</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>author</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>200.222463</td>\n",
              "      <td>1993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16</td>\n",
              "      <td>314.373075</td>\n",
              "      <td>2400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>213.920523</td>\n",
              "      <td>1726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>224.353024</td>\n",
              "      <td>2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>220.964348</td>\n",
              "      <td>1944</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        min        mean   max\n",
              "author                       \n",
              "0        10  200.222463  1993\n",
              "1        16  314.373075  2400\n",
              "2        10  213.920523  1726\n",
              "3        10  224.353024  2500\n",
              "4         9  220.964348  1944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3Hxqi1SWKUBW",
        "outputId": "6d9bc0b8-b8fd-49a7-d032-efb8d3c50204"
      },
      "source": [
        "train_data.loc[train_data['author'] == 3, 'text'].iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'“I see: he heard I had money, and came here to marry me!”'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dvhepyo9vVc"
      },
      "source": [
        "with open('corpus.txt', 'w') as f:\n",
        "    for text in train_data['text']:\n",
        "        f.write(text)\n",
        "        f.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nOgD2vQo_CiC",
        "outputId": "4c895e55-6805-4acb-ce57-2d1d82e51e78"
      },
      "source": [
        "input_file = 'corpus.txt'\n",
        "pad_id = 0 \n",
        "bos_id = 1\n",
        "eos_id = 2\n",
        "unk_id = 3\n",
        "vocab_size = NUM_TOKEN # vocab 사이즈\n",
        "prefix = 'bpe_tokenizer' # 저장될 tokenizer 모델에 붙는 이름\n",
        "model_type ='bpe'\n",
        "\n",
        "cmd = f'--input={input_file} \\\n",
        "--pad_id={pad_id} \\\n",
        "--bos_id={bos_id} \\\n",
        "--eos_id={eos_id} \\\n",
        "--unk_id={unk_id} \\\n",
        "--vocab_size={vocab_size} \\\n",
        "--model_prefix={prefix} \\\n",
        "--model_type={model_type}'\n",
        "\n",
        "cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'--input=corpus.txt --pad_id=0 --bos_id=1 --eos_id=2 --unk_id=3 --vocab_size=10000 --model_prefix=bpe_tokenizer --model_type=bpe'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHpHVDGo93-0"
      },
      "source": [
        "spm.SentencePieceTrainer.Train(cmd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21cjSxeF94_U",
        "outputId": "aca38c48-cef5-47e6-b288-4544d80b4d27"
      },
      "source": [
        "tokenizer = spm.SentencePieceProcessor()\n",
        "tokenizer.load('bpe_tokenizer.model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcmGgbD7_52m"
      },
      "source": [
        "split_idx = int(len(train_data) * 0.2)\n",
        "random_idx = np.random.permutation(len(train_data))\n",
        "\n",
        "train_idx = random_idx[split_idx:]\n",
        "val_idx = random_idx[:split_idx]\n",
        "\n",
        "val_data = train_data.iloc[val_idx]\n",
        "train_data = train_data.iloc[train_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxjKqWCyADD1"
      },
      "source": [
        "train_loader = Dataloader(train_data, tokenizer, 'train')\n",
        "val_loader = Dataloader(val_data, tokenizer, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxCDKo3s_621",
        "outputId": "e54a9eeb-2d04-4a76-d934-cfffc95f6e3e"
      },
      "source": [
        "x, y = train_loader.__getitem__(0)\n",
        "x.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 128), (32,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elnPbAxbAvR-"
      },
      "source": [
        "## 3. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "015DBR5ZAwmd"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "def gelu(x):\n",
        "    cdf = 0.5 * (1.0 + tf.math.erf(x / tf.sqrt(2.0)))\n",
        "    return x * cdf\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True) \n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1) \n",
        "    output = tf.matmul(attention_weights, v)  \n",
        "    return output, attention_weights\n",
        "\n",
        "\n",
        "class Embedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_token, model_dim, max_len, drop_rate):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.token_embedding = tf.keras.layers.Embedding(num_token, model_dim, mask_zero=False, input_length=max_len)\n",
        "        self.pos_embedding = tf.keras.layers.Embedding(max_len, model_dim, mask_zero=False, input_length=max_len)\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout = tf.keras.layers.Dropout(drop_rate)\n",
        "        self.pos = tf.range(0, max_len)\n",
        "    \n",
        "    def call(self, x, training):\n",
        "        token_embedded = self.token_embedding(x)\n",
        "        pos_embedded = self.pos_embedding(self.pos)\n",
        "        pos_embedded = pos_embedded[None,:,:]\n",
        "        embedded = pos_embedded + token_embedded\n",
        "        embedded = self.layernorm(embedded)\n",
        "        embedded = self.dropout(embedded, training=training)\n",
        "        return embedded\n",
        "\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, model_dim, num_head):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_head = num_head\n",
        "        self.model_dim = model_dim\n",
        "        self.depth = model_dim // num_head\n",
        "        assert model_dim % num_head == 0\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(model_dim)\n",
        "        self.wk = tf.keras.layers.Dense(model_dim)\n",
        "        self.wv = tf.keras.layers.Dense(model_dim)\n",
        "        self.dense = tf.keras.layers.Dense(model_dim)\n",
        "        \n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_head, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "    def call(self, q, k, v, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "        \n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "        \n",
        "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "        \n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.model_dim))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)            \n",
        "        return output, attention_weights\n",
        "\n",
        "\n",
        "class PointWiseFeedForward(tf.keras.layers.Layer):\n",
        "    def __init__(self, model_dim, dff):\n",
        "        super(PointWiseFeedForward, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(dff)\n",
        "        self.dense2 = tf.keras.layers.Dense(model_dim)\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.dense1(x)\n",
        "        x = gelu(x)\n",
        "        x = self.dense2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, model_dim, num_head, dff, drop_rate):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(model_dim, num_head)\n",
        "        self.pwff = PointWiseFeedForward(model_dim, dff)\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(drop_rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(drop_rate)\n",
        "        \n",
        "    def call(self, x, mask, training):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "        \n",
        "        pwff_output = self.pwff(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        pwff_output = self.dropout2(pwff_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + pwff_output)  # (batch_size, input_seq_len, d_model)\n",
        "        return out2\n",
        "\n",
        "class OutputLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, model_dim, drop_rate):\n",
        "        super(OutputLayer, self).__init__()\n",
        "        self.pool = tf.keras.layers.GlobalAvgPool1D()\n",
        "        self.dense1 = tf.keras.layers.Dense(model_dim / 2, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(5, activation='softmax')\n",
        "        self.dropout = tf.keras.layers.Dropout(drop_rate)\n",
        "    \n",
        "    def call(self, x, training):\n",
        "        # x = x[:, 0]\n",
        "        x = self.pool(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dropout(x, training)\n",
        "        x = self.dense2(x)\n",
        "        return x\n",
        "\n",
        "class Model(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.embedding = Embedding(NUM_TOKEN, MODEL_DIM, MAX_LENGTH, DROP_RATE)\n",
        "        self.encoder_layers = [EncoderLayer(MODEL_DIM, NUM_HEAD, DFF, DROP_RATE) for _ in range(NUM_LAYER)]\n",
        "        self.output_layer = OutputLayer(MODEL_DIM, DROP_RATE)\n",
        "    \n",
        "    def call(self, x, training):\n",
        "        mask = create_padding_mask(x)\n",
        "        x = self.embedding(x)\n",
        "        for i in range(NUM_LAYER):\n",
        "            x = self.encoder_layers[i](x, mask, training)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6p9zPdrCNaT",
        "outputId": "a05cdc04-c85a-4d67-ea0e-e9d8b51749b9"
      },
      "source": [
        "model = Model()\n",
        "_ = model(x)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_27 (Embedding)     multiple                  1296640   \n",
            "_________________________________________________________________\n",
            "encoder_layer_36 (EncoderLay multiple                  99584     \n",
            "_________________________________________________________________\n",
            "encoder_layer_37 (EncoderLay multiple                  99584     \n",
            "_________________________________________________________________\n",
            "encoder_layer_38 (EncoderLay multiple                  99584     \n",
            "_________________________________________________________________\n",
            "encoder_layer_39 (EncoderLay multiple                  99584     \n",
            "_________________________________________________________________\n",
            "output_layer_9 (OutputLayer) multiple                  8581      \n",
            "=================================================================\n",
            "Total params: 1,703,557\n",
            "Trainable params: 1,703,557\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21E86gjzDeg2"
      },
      "source": [
        "model.compile(\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics = ['acc'],\n",
        "    optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp2VsllxDQRN"
      },
      "source": [
        "## 4. Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRZGfE9-DSud",
        "outputId": "f3f68f9d-6a79-4f66-e3c0-07246953e6f1"
      },
      "source": [
        "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    'model.h5', save_best_only=True, save_weights_only=True\n",
        ")\n",
        "\n",
        "hist = model.fit(\n",
        "    train_loader,\n",
        "    validation_data = val_loader,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    epochs = EPOCH_SIZE,\n",
        "    callbacks = [ckpt_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1372/1372 [==============================] - 52s 38ms/step - loss: 1.1401 - acc: 0.5470 - val_loss: 0.7999 - val_acc: 0.7021\n",
            "Epoch 2/10\n",
            "1372/1372 [==============================] - 53s 38ms/step - loss: 0.6969 - acc: 0.7465 - val_loss: 0.6439 - val_acc: 0.7677\n",
            "Epoch 3/10\n",
            "1372/1372 [==============================] - 52s 38ms/step - loss: 0.5404 - acc: 0.8067 - val_loss: 0.5924 - val_acc: 0.7926\n",
            "Epoch 4/10\n",
            "1372/1372 [==============================] - 52s 38ms/step - loss: 0.4494 - acc: 0.8397 - val_loss: 0.6176 - val_acc: 0.7933\n",
            "Epoch 5/10\n",
            "1372/1372 [==============================] - 52s 38ms/step - loss: 0.3842 - acc: 0.8624 - val_loss: 0.6294 - val_acc: 0.7959\n",
            "Epoch 6/10\n",
            "1372/1372 [==============================] - 52s 38ms/step - loss: 0.3387 - acc: 0.8810 - val_loss: 0.6345 - val_acc: 0.7964\n",
            "Epoch 7/10\n",
            "1372/1372 [==============================] - 53s 38ms/step - loss: 0.2988 - acc: 0.8964 - val_loss: 0.7063 - val_acc: 0.7924\n",
            "Epoch 8/10\n",
            "1372/1372 [==============================] - 53s 39ms/step - loss: 0.2680 - acc: 0.9055 - val_loss: 0.7480 - val_acc: 0.7933\n",
            "Epoch 9/10\n",
            "1372/1372 [==============================] - 53s 38ms/step - loss: 0.2381 - acc: 0.9167 - val_loss: 0.7927 - val_acc: 0.7949\n",
            "Epoch 10/10\n",
            "1372/1372 [==============================] - 54s 39ms/step - loss: 0.2122 - acc: 0.9258 - val_loss: 0.8401 - val_acc: 0.7956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "r9a8m3kbDir9",
        "outputId": "f7726c44-f525-47d7-9fa7-cbc8faf9f3ad"
      },
      "source": [
        "model.load_weights('model.h5')\n",
        "\n",
        "train_true = train_data['author']\n",
        "train_loader = Dataloader(train_data, tokenizer, 'test')\n",
        "train_prob = model.predict(train_loader)\n",
        "train_pred = np.argmax(train_prob, axis=1)\n",
        "train_loss = np.mean(tf.keras.losses.sparse_categorical_crossentropy(train_true, train_prob))\n",
        "train_acc = np.mean(train_true == train_pred)\n",
        "\n",
        "val_true = val_data['author']\n",
        "val_loader = Dataloader(val_data, tokenizer, 'test')\n",
        "val_prob = model.predict(val_loader)\n",
        "val_pred = np.argmax(val_prob, axis=1)\n",
        "val_loss = np.mean(tf.keras.losses.sparse_categorical_crossentropy(val_true, val_prob))\n",
        "val_acc = np.mean(val_true == val_pred)\n",
        "\n",
        "train_cfm = confusion_matrix(train_true, train_pred, normalize='true')\n",
        "val_cfm = confusion_matrix(val_true, val_pred, normalize='true')\n",
        "\n",
        "print(f'train loss : {train_loss:.4f} | val loss : {val_loss:.4f}')\n",
        "print(f'train acc  : {train_acc:.4f}  | val acc  : {val_acc:.4f}')\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(7, 3))\n",
        "sns.heatmap(train_cfm, ax=ax[0])\n",
        "sns.heatmap(val_cfm, ax=ax[1])\n",
        "\n",
        "ax[0].set_title('Train Confusion Matrix')\n",
        "ax[1].set_title('Validation Confusion Matrix')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train loss : 0.3384 | val loss : 0.5924\n",
            "train acc  : 0.8817  | val acc  : 0.7926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x216 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMSHNVpWDplr"
      },
      "source": [
        "## 5. Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "OyIa_Y0qDqRV",
        "outputId": "70d00cab-9d73-49cf-8945-b5770ce90699"
      },
      "source": [
        "test_data = pd.read_csv('data/test_x.csv')\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>“Not at all. I think she is one of the most ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>As the lady had stated her intention of scream...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>“And then suddenly in the silence I heard a so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>His conviction remained unchanged. So far as I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                               text\n",
              "0      0  “Not at all. I think she is one of the most ch...\n",
              "1      1  \"No,\" replied he, with sudden consciousness, \"...\n",
              "2      2  As the lady had stated her intention of scream...\n",
              "3      3  “And then suddenly in the silence I heard a so...\n",
              "4      4  His conviction remained unchanged. So far as I..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "0Dh-BldPDrmt",
        "outputId": "3edb6bd2-eee3-42a4-82d7-f4a911419cd5"
      },
      "source": [
        "submission = pd.read_csv('data/sample_submission.csv')\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  0  1  2  3  4\n",
              "0      0  0  0  0  0  0\n",
              "1      1  0  0  0  0  0\n",
              "2      2  0  0  0  0  0\n",
              "3      3  0  0  0  0  0\n",
              "4      4  0  0  0  0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_UzwZVODscN"
      },
      "source": [
        "test_loader = Dataloader(test_data, tokenizer, 'test')\n",
        "test_pred = model.predict(test_loader)\n",
        "submission[['0', '1', '2', '3', '4']] = test_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ciEfmGJ0DtY0",
        "outputId": "1dd8394d-0539-4b98-b67d-a58c9636c838"
      },
      "source": [
        "submission.to_csv('submission.csv', index=False)\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.010309</td>\n",
              "      <td>0.783180</td>\n",
              "      <td>0.200585</td>\n",
              "      <td>0.005426</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.001642</td>\n",
              "      <td>0.993249</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>0.004015</td>\n",
              "      <td>0.000847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.998716</td>\n",
              "      <td>0.000881</td>\n",
              "      <td>0.000239</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.005959</td>\n",
              "      <td>0.007133</td>\n",
              "      <td>0.950626</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.036159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.995304</td>\n",
              "      <td>0.003235</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>0.000994</td>\n",
              "      <td>0.000328</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index         0         1         2         3         4\n",
              "0      0  0.010309  0.783180  0.200585  0.005426  0.000500\n",
              "1      1  0.001642  0.993249  0.000248  0.004015  0.000847\n",
              "2      2  0.998716  0.000881  0.000239  0.000046  0.000119\n",
              "3      3  0.005959  0.007133  0.950626  0.000124  0.036159\n",
              "4      4  0.995304  0.003235  0.000139  0.000994  0.000328"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEpVkDYUILXu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}